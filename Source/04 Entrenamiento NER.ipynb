{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from globals import TRAINING_DIR,MODELS_DIR, DATA_DIR, id2label,label2id\n",
    "import mlflow\n",
    "from datasets import load_dataset\n",
    "import requests\n",
    "from transformers import (\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    pipeline)\n",
    "from pprint import PrettyPrinter\n",
    "from numpy import argmax\n",
    "from torch.cuda import is_available as cuda_is_available\n",
    "from metrics.evaluar_metricas import evaluar_metricas_NER\n",
    "from seqeval.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from datetime import datetime\n",
    "from globals import ner_predicted_labels, group_by_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definición de variables globales, parámetros de entrenamiento y MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLES GLOBALES\n",
    "train_max = None # Número máximo de elementos para entrenamiento (para pruebas) None para ir en serio\n",
    "training_output_dir = os.path.join(TRAINING_DIR,\"NER\")\n",
    "# Defino una serie de variables que registraré en los entrenamientos de MLflow\n",
    "ml_params = {\n",
    "    'num_epochs': 3,\n",
    "    'lr' : 1e-5,\n",
    "    'eval_steps' : 0.05, \n",
    "    'eval_batch_size' : 64,\n",
    "    'label_all_tokens': True,\n",
    "    'model_name': os.path.join(MODELS_DIR,'PlanTL-GOB-ES','roberta-base-bne-capitel-ner-plus')\n",
    "}\n",
    "num_epochs = lr = eval_steps = eval_batch_size = label_all_tokens = model_name = 0\n",
    "for key, value in ml_params.items():\n",
    "    assert not globals()[key] is None, f'La variable global {key} debe estar definida'    \n",
    "    globals()[key] = value\n",
    "\n",
    "pp = PrettyPrinter(width=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga del conjunto de datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dataset = load_dataset(os.path.join(DATA_DIR,'Escrituras'), 'NER',trust_remote_code=True)\n",
    "train_dataset = main_dataset['train']\n",
    "val_dataset = main_dataset['validation']\n",
    "if train_max:\n",
    "    train_dataset = train_dataset.select(range(train_max))\n",
    "    val_dataset = val_dataset.select(range(train_max))\n",
    "del main_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobación de que el servidor MLflow está funcionando para las pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVIDOR_MLFLOW = 'http://localhost:5000'\n",
    "# Debo comprobar si está ejecutando el servidor MLflow, en otro caso se demora la ejecución y acaba dando un error\n",
    "def mlflow_en_ejecucion(url):\n",
    "    try:\n",
    "        response = requests.get(url)        \n",
    "        # Si el servidor está en ejecución, deberíamos recibir un código de estado HTTP 200\n",
    "        return response.status_code == 200\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        # Si no se puede establecer una conexión, asumimos que el servidor no está en ejecución\n",
    "        return False\n",
    "    \n",
    "assert mlflow_en_ejecucion(SERVIDOR_MLFLOW), f\"El servidor MLflow ({SERVIDOR_MLFLOW}) no está en ejecución. Lance 'mlflow ui' desde el terminal.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iniciamos el entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicio del servidor MLflow para registrar los entrenamientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/18 19:49:08 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2024/02/18 19:49:08 INFO mlflow.tracking.fluent: Autologging successfully enabled for transformers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/826943604288671220', creation_time=1708271990580, experiment_id='826943604288671220', last_update_time=1708271990580, lifecycle_stage='active', name='03 ENTRENAMIENTO Named Entity Recognition', tags={}>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Servidor de seguimiento\n",
    "mlflow.set_tracking_uri(SERVIDOR_MLFLOW)\n",
    "mlflow.autolog()\n",
    "mlflow.set_experiment(\"03 ENTRENAMIENTO Named Entity Recognition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at ..\\Models\\PlanTL-GOB-ES\\roberta-base-bne-capitel-ner-plus and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([17, 768]) in the checkpoint and torch.Size([9, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([17]) in the checkpoint and torch.Size([9]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Cargo la lista de etiquetas definidas en el dataset\n",
    "lista_etiquetas = train_dataset.features['ner_tags'].feature.names\n",
    "\n",
    "model  = AutoModelForTokenClassification.from_pretrained(model_name, \n",
    "                                                         num_labels=len(lista_etiquetas), ignore_mismatched_sizes=True,\n",
    "                                                         id2label=id2label,label2id=label2id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetInfo(description='Dataset para entrenamiento de modelos NER en extracción de datos de escrituras.\\n'\n",
      "                        '                                    Las etiquetas utilizadas se corresponden con los siguientes elementos:\\n'\n",
      "                        \"                                    'B-PROTO','I-PROTO':    Número de PROTOCOLO.\\n\"\n",
      "                        \"                                    'B-FDOC','I-FDOC':      FECHA de firma del DOCUMENTO.\\n\"\n",
      "                        \"                                    'B-NOT','I-NOT':        NOTARIO, nombre y apellidos.\\n\"\n",
      "                        \"                                    'B-TDOC','I-TDOC':      TIPO de DOCUMENTO.\\n\"\n",
      "                        '                                ',\n",
      "            citation='',\n",
      "            homepage='',\n",
      "            license='',\n",
      "            features={'id': Value(dtype='string', id=None),\n",
      "                      'ner_tags': Sequence(feature=ClassLabel(names=['O',\n",
      "                                                                     'B-PROTO',\n",
      "                                                                     'I-PROTO',\n",
      "                                                                     'B-FDOC',\n",
      "                                                                     'I-FDOC',\n",
      "                                                                     'B-NOT',\n",
      "                                                                     'I-NOT',\n",
      "                                                                     'B-TDOC',\n",
      "                                                                     'I-TDOC'],\n",
      "                                                              id=None),\n",
      "                                           length=-1,\n",
      "                                           id=None),\n",
      "                      'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)},\n",
      "            post_processed=None,\n",
      "            supervised_keys=None,\n",
      "            task_templates=None,\n",
      "            builder_name='escrituras',\n",
      "            dataset_name='escrituras',\n",
      "            config_name='NER',\n",
      "            version=0.0.0,\n",
      "            splits={'test': SplitInfo(name='test', num_bytes=7462889, num_examples=1883, shard_lengths=None, dataset_name='escrituras'),\n",
      "                    'train': SplitInfo(name='train', num_bytes=23787339, num_examples=6024, shard_lengths=None, dataset_name='escrituras'),\n",
      "                    'validation': SplitInfo(name='validation', num_bytes=5962213, num_examples=1507, shard_lengths=None, dataset_name='escrituras')},\n",
      "            download_checksums={'NER_test.json': {'checksum': None, 'num_bytes': 7730085},\n",
      "                                'NER_train.json': {'checksum': None, 'num_bytes': 24632197},\n",
      "                                'NER_validation.json': {'checksum': None, 'num_bytes': 6173699}},\n",
      "            download_size=38535981,\n",
      "            post_processing_size=None,\n",
      "            dataset_size=37212441,\n",
      "            size_in_bytes=75748422)\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(train_dataset.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones de preprocesado y evaluación de métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_preproceso(examples):\n",
    "    \"\"\"Función para generar los input_ids, atention_mask y otras características para el entrenamiento.\n",
    "        Realinea los 'ner_tags' que\"\"\"        \n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], is_split_into_words=True, truncation=True, padding=True)\n",
    "    \n",
    "    ner_tags_ids = []\n",
    "    for i, tags in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # indica de qué palabra viene cada token\n",
    "        previous_word_idx = None\n",
    "        tag_ids = []\n",
    "        for word_idx in word_ids:  \n",
    "            # Tokens especiales van a -100 para ser ignorados por la función de pérdida.\n",
    "            if word_idx is None:\n",
    "                tag_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  \n",
    "                tag_ids.append(tags[word_idx])\n",
    "            else:\n",
    "                # Hay dos estrategias:\n",
    "                # Sólo se etiqueta la primera aparición de cada palabra\n",
    "                # o se etiquetan todos los tokens de cada palabra\n",
    "                tag_ids.append(tags[word_idx] if ml_params['label_all_tokens'] else -100)                \n",
    "            previous_word_idx = word_idx\n",
    "        ner_tags_ids.append(tag_ids)\n",
    "\n",
    "    # Sustituyo la actual característica 'labels' que debe cambiar al realizar la tokenización de las entradas\n",
    "    tokenized_inputs[\"labels\"] = ner_tags_ids\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4635e0acc554c858bf510d4cb393f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6024 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "025faa9cfcdb4b70b741d4c9cf13104e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1507 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(f_preproceso, batched=True)\n",
    "tokenized_val_dataset = val_dataset.map(f_preproceso,batched=True)\n",
    "del train_dataset\n",
    "del val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetInfo(description='Dataset para entrenamiento de modelos NER en extracción de datos de escrituras.\\n'\n",
      "                        '                                    Las etiquetas utilizadas se corresponden con los siguientes elementos:\\n'\n",
      "                        \"                                    'B-PROTO','I-PROTO':    Número de PROTOCOLO.\\n\"\n",
      "                        \"                                    'B-FDOC','I-FDOC':      FECHA de firma del DOCUMENTO.\\n\"\n",
      "                        \"                                    'B-NOT','I-NOT':        NOTARIO, nombre y apellidos.\\n\"\n",
      "                        \"                                    'B-TDOC','I-TDOC':      TIPO de DOCUMENTO.\\n\"\n",
      "                        '                                ',\n",
      "            citation='',\n",
      "            homepage='',\n",
      "            license='',\n",
      "            features={'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
      "                      'id': Value(dtype='string', id=None),\n",
      "                      'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
      "                      'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
      "                      'ner_tags': Sequence(feature=ClassLabel(names=['O',\n",
      "                                                                     'B-PROTO',\n",
      "                                                                     'I-PROTO',\n",
      "                                                                     'B-FDOC',\n",
      "                                                                     'I-FDOC',\n",
      "                                                                     'B-NOT',\n",
      "                                                                     'I-NOT',\n",
      "                                                                     'B-TDOC',\n",
      "                                                                     'I-TDOC'],\n",
      "                                                              id=None),\n",
      "                                           length=-1,\n",
      "                                           id=None),\n",
      "                      'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)},\n",
      "            post_processed=None,\n",
      "            supervised_keys=None,\n",
      "            task_templates=None,\n",
      "            builder_name='escrituras',\n",
      "            dataset_name='escrituras',\n",
      "            config_name='NER',\n",
      "            version=0.0.0,\n",
      "            splits={'test': SplitInfo(name='test', num_bytes=7462889, num_examples=1883, shard_lengths=None, dataset_name='escrituras'),\n",
      "                    'train': SplitInfo(name='train', num_bytes=23787339, num_examples=6024, shard_lengths=None, dataset_name='escrituras'),\n",
      "                    'validation': SplitInfo(name='validation', num_bytes=5962213, num_examples=1507, shard_lengths=None, dataset_name='escrituras')},\n",
      "            download_checksums={'NER_test.json': {'checksum': None, 'num_bytes': 7730085},\n",
      "                                'NER_train.json': {'checksum': None, 'num_bytes': 24632197},\n",
      "                                'NER_validation.json': {'checksum': None, 'num_bytes': 6173699}},\n",
      "            download_size=38535981,\n",
      "            post_processing_size=None,\n",
      "            dataset_size=37212441,\n",
      "            size_in_bytes=75748422)\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(tokenized_train_dataset.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de evaluación \n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = argmax(predictions, axis=2)\n",
    "\n",
    "    predictions_list = [\n",
    "        [lista_etiquetas[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [lista_etiquetas[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision_score(true_labels, predictions_list),\n",
    "        \"recall\":   recall_score(true_labels, predictions_list),\n",
    "        \"f1_score\": f1_score(true_labels, predictions_list),\n",
    "        \"accuracy\": accuracy_score(true_labels, predictions_list)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definición de los parámetros y el trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=training_output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    do_train=True,\n",
    "    learning_rate=lr,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=eval_steps,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=eval_steps,    \n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1_score'    \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,    \n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/18 19:49:22 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2024/02/18 19:49:22 INFO mlflow.tracking.fluent: Autologging successfully enabled for transformers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a6b72fe23274efb815ddf9ddca27bbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2259 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e92272ded0d94a3caa53adcc7b78b786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.036558691412210464, 'eval_precision': 0.8889960614098545, 'eval_recall': 0.7965430320489737, 'eval_f1_score': 0.8402339892121857, 'eval_accuracy': 0.9917805069049958, 'eval_runtime': 17.236, 'eval_samples_per_second': 87.433, 'eval_steps_per_second': 1.392, 'epoch': 0.15}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714976ef7faa43cda8fcbf5f16064d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.013875742442905903, 'eval_precision': 0.9355610321832415, 'eval_recall': 0.9295642779978394, 'eval_f1_score': 0.932553014703226, 'eval_accuracy': 0.9969048714092158, 'eval_runtime': 17.177, 'eval_samples_per_second': 87.734, 'eval_steps_per_second': 1.397, 'epoch': 0.3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09bab667d0714864accf8149c37ba275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.008487021550536156, 'eval_precision': 0.9635219226092554, 'eval_recall': 0.9701836514223983, 'eval_f1_score': 0.9668413119931099, 'eval_accuracy': 0.9982162612338251, 'eval_runtime': 17.039, 'eval_samples_per_second': 88.444, 'eval_steps_per_second': 1.409, 'epoch': 0.45}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5718c9a55d7d4794b63e539f0d64d643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00683123804628849, 'eval_precision': 0.9711723254324152, 'eval_recall': 0.9826431400792222, 'eval_f1_score': 0.9768740602849574, 'eval_accuracy': 0.998527017116434, 'eval_runtime': 17.139, 'eval_samples_per_second': 87.928, 'eval_steps_per_second': 1.4, 'epoch': 0.6}\n",
      "{'loss': 0.0884, 'learning_rate': 7.786631252766713e-06, 'epoch': 0.66}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6234efb0507f43278bf3c3b829b3ea5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.007308057509362698, 'eval_precision': 0.9818529130850048, 'eval_recall': 0.9624774936982355, 'eval_f1_score': 0.972068664533023, 'eval_accuracy': 0.9981649865131947, 'eval_runtime': 17.107, 'eval_samples_per_second': 88.093, 'eval_steps_per_second': 1.403, 'epoch': 0.75}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b42841eab1ff4f06935888f7575ad28f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.004757819697260857, 'eval_precision': 0.9816658311251164, 'eval_recall': 0.9871804105149442, 'eval_f1_score': 0.9844153978741742, 'eval_accuracy': 0.998982274484456, 'eval_runtime': 17.06, 'eval_samples_per_second': 88.335, 'eval_steps_per_second': 1.407, 'epoch': 0.9}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a99b87f5d88348d084f8318f7d9b03fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.004728749394416809, 'eval_precision': 0.9802156988786516, 'eval_recall': 0.9884047533309327, 'eval_f1_score': 0.9842931937172775, 'eval_accuracy': 0.9989434299991299, 'eval_runtime': 17.071, 'eval_samples_per_second': 88.278, 'eval_steps_per_second': 1.406, 'epoch': 1.05}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cf777b4257a48c0a522f0f6860f0e8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0038392606656998396, 'eval_precision': 0.9864592336502449, 'eval_recall': 0.986388188692834, 'eval_f1_score': 0.986423709892326, 'eval_accuracy': 0.9991438675434126, 'eval_runtime': 17.169, 'eval_samples_per_second': 87.774, 'eval_steps_per_second': 1.398, 'epoch': 1.2}\n",
      "{'loss': 0.0043, 'learning_rate': 5.573262505533422e-06, 'epoch': 1.33}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83051c9eae024463a8934f62b41a724e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0035473830066621304, 'eval_precision': 0.9868847733660013, 'eval_recall': 0.9863161685271876, 'eval_f1_score': 0.9866003890209638, 'eval_accuracy': 0.99926506233763, 'eval_runtime': 17.293, 'eval_samples_per_second': 87.145, 'eval_steps_per_second': 1.388, 'epoch': 1.35}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e1a18f7a014e7fb3942d9fdfbcf3ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.003044114913791418, 'eval_precision': 0.989986312225344, 'eval_recall': 0.9897011163125675, 'eval_f1_score': 0.9898436937261398, 'eval_accuracy': 0.9993738268965432, 'eval_runtime': 17.014, 'eval_samples_per_second': 88.574, 'eval_steps_per_second': 1.411, 'epoch': 1.5}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5083579a46134394bd4b272fb9f4f846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0028446216601878405, 'eval_precision': 0.9896566585260739, 'eval_recall': 0.9922938422758373, 'eval_f1_score': 0.9909734958823319, 'eval_accuracy': 0.9994468545289562, 'eval_runtime': 17.183, 'eval_samples_per_second': 87.703, 'eval_steps_per_second': 1.397, 'epoch': 1.65}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a90f4e7c9684843a7663b977fd49679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0027299632783979177, 'eval_precision': 0.9919250180245134, 'eval_recall': 0.9908534389629096, 'eval_f1_score': 0.9913889389299225, 'eval_accuracy': 0.9994934679113475, 'eval_runtime': 17.148, 'eval_samples_per_second': 87.882, 'eval_steps_per_second': 1.4, 'epoch': 1.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce2cd7503f24f7991f54055b3fe0f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0031106192618608475, 'eval_precision': 0.9894842984730625, 'eval_recall': 0.989413035649982, 'eval_f1_score': 0.989448665778386, 'eval_accuracy': 0.9993847033524345, 'eval_runtime': 17.111, 'eval_samples_per_second': 88.072, 'eval_steps_per_second': 1.403, 'epoch': 1.95}\n",
      "{'loss': 0.0025, 'learning_rate': 3.359893758300133e-06, 'epoch': 1.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1daee5d817741ec97bebde11ad2b625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.002760678995400667, 'eval_precision': 0.9903555491579099, 'eval_recall': 0.9909974792942023, 'eval_f1_score': 0.9906764102379496, 'eval_accuracy': 0.9994468545289562, 'eval_runtime': 17.107, 'eval_samples_per_second': 88.092, 'eval_steps_per_second': 1.403, 'epoch': 2.1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd954e4419e42ab858b54223d099acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.002778151072561741, 'eval_precision': 0.9883287985106688, 'eval_recall': 0.9940943464169968, 'eval_f1_score': 0.9912031883953898, 'eval_accuracy': 0.9994515158671954, 'eval_runtime': 16.713, 'eval_samples_per_second': 90.169, 'eval_steps_per_second': 1.436, 'epoch': 2.25}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac79ad2caa74349b169a7bec661c47e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.002621967811137438, 'eval_precision': 0.9912192313228732, 'eval_recall': 0.9918617212819589, 'eval_f1_score': 0.9915403722236221, 'eval_accuracy': 0.9994856990142823, 'eval_runtime': 16.638, 'eval_samples_per_second': 90.576, 'eval_steps_per_second': 1.442, 'epoch': 2.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b837a1dbd20f4011bb2658ad1a3cca3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.002713553374633193, 'eval_precision': 0.9897292250233427, 'eval_recall': 0.99243788260713, 'eval_f1_score': 0.9910817031070197, 'eval_accuracy': 0.9994142251612823, 'eval_runtime': 16.74, 'eval_samples_per_second': 90.024, 'eval_steps_per_second': 1.434, 'epoch': 2.55}\n",
      "{'loss': 0.0015, 'learning_rate': 1.1465250110668438e-06, 'epoch': 2.66}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f884d4fe26241c3933b28141b3cb85c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0026107176672667265, 'eval_precision': 0.9911555331847272, 'eval_recall': 0.9927259632697155, 'eval_f1_score': 0.9919401266551525, 'eval_accuracy': 0.9994763763378041, 'eval_runtime': 16.773, 'eval_samples_per_second': 89.847, 'eval_steps_per_second': 1.431, 'epoch': 2.7}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9da62dd7f214b8492abaca7f46e5210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0025513186119496822, 'eval_precision': 0.9910078411625063, 'eval_recall': 0.9921498019445445, 'eval_f1_score': 0.9915784927661412, 'eval_accuracy': 0.9994763763378041, 'eval_runtime': 16.754, 'eval_samples_per_second': 89.948, 'eval_steps_per_second': 1.432, 'epoch': 2.85}\n",
      "{'train_runtime': 815.0988, 'train_samples_per_second': 22.172, 'train_steps_per_second': 2.771, 'train_loss': 0.0215389627094235, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=f\"{'Prueba con ' + str(train_max) if train_max else 'Entrenamiento'}\"):\n",
    "    mlflow.autolog()\n",
    "    trainer.train()\n",
    "    for param_name, param_value in ml_params.items():\n",
    "        mlflow.log_param(param_name, param_value)    \n",
    "    # Guardar el modelo    \n",
    "    n_epochs = trainer.args.num_train_epochs\n",
    "    g_steps = trainer.state.global_step\n",
    "    fecha_hora = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "    ruta_modelo_ajustado = os.path.join(MODELS_DIR,f\"{fecha_hora}_escrituras_NER_{n_epochs}-epoch_{g_steps}-steps\")\n",
    "    trainer.save_model(ruta_modelo_ajustado)\n",
    "    tokenizer.save_pretrained(ruta_modelo_ajustado)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('..\\\\Models\\\\20240218-2002_escrituras_NER_3-epoch_2259-steps\\\\tokenizer_config.json',\n",
       " '..\\\\Models\\\\20240218-2002_escrituras_NER_3-epoch_2259-steps\\\\special_tokens_map.json',\n",
       " '..\\\\Models\\\\20240218-2002_escrituras_NER_3-epoch_2259-steps\\\\vocab.json',\n",
       " '..\\\\Models\\\\20240218-2002_escrituras_NER_3-epoch_2259-steps\\\\merges.txt',\n",
       " '..\\\\Models\\\\20240218-2002_escrituras_NER_3-epoch_2259-steps\\\\added_tokens.json',\n",
       " '..\\\\Models\\\\20240218-2002_escrituras_NER_3-epoch_2259-steps\\\\tokenizer.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = trainer.args.num_train_epochs\n",
    "g_steps = trainer.state.global_step\n",
    "fecha_hora = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "ruta_modelo_ajustado = os.path.join(MODELS_DIR,f\"{fecha_hora}_escrituras_NER_{n_epochs}-epoch_{g_steps}-steps\")\n",
    "trainer.save_model(ruta_modelo_ajustado)\n",
    "tokenizer.save_pretrained(ruta_modelo_ajustado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba de resultados para ver cómo predice en comparación con un ejemplo del conjunto de pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained('..\\\\Models\\\\20240218-2002_escrituras_NER_3-epoch_2259-steps')\n",
    "tokenizer = AutoTokenizer.from_pretrained('..\\\\Models\\\\20240218-2002_escrituras_NER_3-epoch_2259-steps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'PROTO', 'matches': [{'start': 7, 'text': 'siete mil doscientos siete'}]},\n",
      " {'label': 'TDOC', 'matches': [{'start': 76, 'text': 'HERENCIA'}]},\n",
      " {'label': 'FDOC', 'matches': [{'start': 125, 'text': 'veinte de junio de dos mil veintiuno'}]},\n",
      " {'label': 'NOT', 'matches': [{'start': 174, 'text': 'TARU ELINA BENTANCUR'}]}]\n"
     ]
    }
   ],
   "source": [
    "id_test = 2\n",
    "model.eval()    \n",
    "test_dataset = load_dataset(os.path.join(DATA_DIR,'Escrituras'), 'NER',trust_remote_code=True, split=\"test\")\n",
    "\n",
    "# # Método 3\n",
    "consulta =  pipeline(\"ner\", model=model, tokenizer=tokenizer, \n",
    "                device=0 if cuda_is_available() else None, batch_size=32)        \n",
    "text = \" \".join(test_dataset['tokens'][id_test])\n",
    "predicciones = consulta(text)\n",
    "pp.pprint(group_by_labels(ner_predicted_labels(predicciones,text, tokenizer)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación final con el conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/18 20:03:01 INFO mlflow.tracking.fluent: Autologging successfully enabled for transformers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\Models\\20240218-2002_escrituras_NER_3-epoch_2259-steps\n",
      "..\\Models\\20240218-2002_escrituras_NER_3-epoch_2259-steps\n",
      "\tf1: 0.956537186167693\n",
      "\tprecision: 0.9869257086999023\n",
      "\trecall: 0.9279641544117647\n",
      "\taccuracy: 0.99427895048333\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(SERVIDOR_MLFLOW)\n",
    "mlflow.autolog()\n",
    "mlflow.set_experiment(\"03 ENTRENAMIENTO Named Entity Recognition\")\n",
    "\n",
    "try:\n",
    "    # El entrenamiento NER requiere menos memoria, es posible que no haga falta hacer restart.\n",
    "    print(ruta_modelo_ajustado)\n",
    "except:\n",
    "    # Si hemos tenido he hacer restart del entorno, copiar la ruta del último entrenamiento\n",
    "    ruta_modelo_ajustado = os.path.join(MODELS_DIR,\"20240218-1730_escrituras_NER_5-epoch_3765-steps\")\n",
    "    \n",
    "test_dataset = load_dataset(os.path.join(DATA_DIR,'Escrituras'), 'NER',trust_remote_code=True, split=\"test\")\n",
    "with mlflow.start_run(run_name=\"VALIDACIÓN\",description=\"Validación del modelo NER ajsutado.\"):\n",
    "    evaluar_metricas_NER(ruta_modelo_ajustado,test_dataset)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

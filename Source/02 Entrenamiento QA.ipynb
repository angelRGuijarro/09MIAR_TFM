{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from custom_evaluate import get_raw_scores_by_prediction, compute_exact, compute_f1\n",
    "import evaluate\n",
    "from statistics import mean\n",
    "import mlflow\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, Trainer, TrainingArguments, \\\n",
    "    pipeline, DataCollatorWithPadding\n",
    "import requests\n",
    "import torch\n",
    "import numpy as np\n",
    "import os, shutil\n",
    "import datetime\n",
    "import pprint\n",
    "# Impresión elegante de datos en la terminal\n",
    "pp = pprint.PrettyPrinter(width=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLES GLOBALES\n",
    "train_max = None # Número máximo de elementos para entrenamiento (para pruebas) None para ir en serio\n",
    "training_output_dir = \"../training/QA\"\n",
    "ml_params = {\n",
    "    'num_epochs': 2,\n",
    "    # 'batch_size': 8, \n",
    "    'lr' : 1e-5,\n",
    "    'eval_steps' : 0.05, \n",
    "    'save_steps' : 0.05, \n",
    "    'eval_batch_size' : 128,\n",
    "    'model_name': 'PlanTL-GOB-ES/roberta-large-bne-sqac' \n",
    "}\n",
    "num_epochs = lr = eval_steps = save_steps = eval_batch_size = model_name = 0\n",
    "for key, value in ml_params.items():\n",
    "    assert not globals()[key] is None, f'La variable global {key} debe estar definida'    \n",
    "    globals()[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVIDOR_MLFLOW = 'http://localhost:5000'\n",
    "# Debo comprobar si está ejecutando el servidor MLflow, en otro caso se demora la ejecución y acaba dando un error\n",
    "def mlflow_en_ejecucion(url):\n",
    "    try:\n",
    "        response = requests.get(url)        \n",
    "        # Si el servidor está en ejecución, deberíamos recibir un código de estado HTTP 200\n",
    "        return response.status_code == 200\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        # Si no se puede establecer una conexión, asumimos que el servidor no está en ejecución\n",
    "        return False\n",
    "    \n",
    "assert mlflow_en_ejecucion(SERVIDOR_MLFLOW), f\"El servidor MLflow ({SERVIDOR_MLFLOW}) no está en ejecución. Lance 'mlflow ui' desde el terminal.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/13 20:48:57 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2024/02/13 20:48:57 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of transformers. If you encounter errors during autologging, try upgrading / downgrading transformers to a supported version, or try upgrading MLflow.\n",
      "2024/02/13 20:48:57 INFO mlflow.tracking.fluent: Autologging successfully enabled for transformers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/423598931169215837', creation_time=1707602045463, experiment_id='423598931169215837', last_update_time=1707602045463, lifecycle_stage='active', name='ENTRENAMIENTO Question-Answering', tags={}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Servidor de seguimiento\n",
    "mlflow.set_tracking_uri(SERVIDOR_MLFLOW)\n",
    "mlflow.autolog()\n",
    "mlflow.set_experiment(\"ENTRENAMIENTO Question-Answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dataset = load_dataset('../Dataset/Escrituras', 'QA', trust_remote_code=True)\n",
    "train_dataset = main_dataset['train']\n",
    "val_dataset = main_dataset['validation']\n",
    "if train_max:\n",
    "    train_dataset = train_dataset.select(range(train_max))\n",
    "    val_dataset = val_dataset.select(range(train_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extraído del tuturial en HF sobre Question-Answering\n",
    "def f_preproceso(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=512,\n",
    "        stride=128,\n",
    "        truncation=\"only_second\",\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    labels = []\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        answer = answers[i]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        # la secuencia indica qué tokens son de pregunta y cuales de contexto\n",
    "        sequence_ids = inputs.sequence_ids(i) \n",
    "\n",
    "        # Busca el inicio y el final del contexto\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # Si la pregunta no está íntegra en el contexto etiquetamos con (0,0)\n",
    "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "            labels.append([0,0])\n",
    "        else:\n",
    "            # En otro caso, se encuentra entre los tokens de inicio y final\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start = idx - 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end =idx + 1\n",
    "            end_positions.append(idx + 1)\n",
    "            labels.append([start,end])\n",
    "        \n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    inputs[\"labels\"] = labels \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized = train_dataset.map(f_preproceso,batched=True, remove_columns=train_dataset.column_names)\n",
    "eval_tokenized = val_dataset.map(f_preproceso,batched=True, remove_columns=val_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetInfo(description='',\n",
      "            citation='',\n",
      "            homepage='',\n",
      "            license='',\n",
      "            features={'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
      "                      'end_positions': Value(dtype='int64', id=None),\n",
      "                      'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
      "                      'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
      "                      'start_positions': Value(dtype='int64', id=None)},\n",
      "            post_processed=None,\n",
      "            supervised_keys=None,\n",
      "            task_templates=None,\n",
      "            builder_name='escrituras',\n",
      "            dataset_name='escrituras',\n",
      "            config_name='QA',\n",
      "            version=0.0.0,\n",
      "            splits={'test': SplitInfo(name='test', num_bytes=11287326, num_examples=7532, shard_lengths=None, dataset_name='escrituras'),\n",
      "                    'train': SplitInfo(name='train', num_bytes=35877697, num_examples=24096, shard_lengths=None, dataset_name='escrituras'),\n",
      "                    'validation': SplitInfo(name='validation', num_bytes=8993863, num_examples=6028, shard_lengths=None, dataset_name='escrituras')},\n",
      "            download_checksums={'QA_test.json': {'checksum': None, 'num_bytes': 3699533},\n",
      "                                'QA_train.json': {'checksum': None, 'num_bytes': 11755145},\n",
      "                                'QA_validation.json': {'checksum': None, 'num_bytes': 2945354}},\n",
      "            download_size=18400032,\n",
      "            post_processing_size=None,\n",
      "            dataset_size=56158886,\n",
      "            size_in_bytes=74558918)\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(train_tokenized.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "# metric = evaluate.load('squad_v2')\n",
    "     \n",
    "def compute_metrics(eval_pred):\n",
    "    pred_ini = np.argmax(eval_pred.predictions[0],axis=1)\n",
    "    pred_fin = np.argmax(eval_pred.predictions[1],axis=1)\n",
    "    pred_txt = [tokenizer.decode(tokens[p_ini:p_fin+1]).strip() for tokens,p_ini,p_fin in zip(eval_pred.inputs,pred_ini,pred_fin)]\n",
    "    \n",
    "    gold_ini = eval_pred.label_ids[0]\n",
    "    gold_fin = eval_pred.label_ids[1]\n",
    "    gold_txt = [tokenizer.decode(tokens[g_ini:g_fin+1]).strip() for tokens,g_ini,g_fin in zip(eval_pred.inputs,gold_ini,gold_fin)]\n",
    "    \n",
    "    f1s = [compute_f1(g,p) for g,p in zip(gold_txt,pred_txt)]\n",
    "    ems = [compute_exact(g,p) for g,p in zip(gold_txt,pred_txt)]\n",
    "\n",
    "    # return metric.compute(predictions=eval_pred.predictions, references=eval_pred.label_ids)\n",
    "    return {'f1_score':np.mean(f1s), 'exact_score': np.mean(ems)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrar el directorio de entrenamiento si existe\n",
    "# if os.path.exists(training_output_dir):\n",
    "#     shutil.rmtree(training_output_dir)\n",
    "\n",
    "training_arg = TrainingArguments(\n",
    "    output_dir=training_output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    do_train=True,\n",
    "    learning_rate=lr,\n",
    "    warmup_ratio=0.2,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=eval_steps,\n",
    "    save_strategy='steps',\n",
    "    save_steps=save_steps,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1_score',\n",
    "    logging_steps=eval_steps,\n",
    "    # per_device_train_batch_size=batch_size,\n",
    "    auto_find_batch_size=True,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    include_inputs_for_metrics=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_arg,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=eval_tokenized,    \n",
    "    tokenizer=tokenizer,    \n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed2644c5b4e4cd697fe8dda8804adf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0487, 'learning_rate': 2.506224066390042e-06, 'epoch': 0.1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49975b613ae42a4a80b05c763a1982a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.17089803516864777, 'eval_f1_score': 0.9661937282827577, 'eval_exact_score': 0.9570338420703384, 'eval_runtime': 142.373, 'eval_samples_per_second': 42.339, 'eval_steps_per_second': 0.337, 'epoch': 0.1}\n",
      "{'loss': 0.1365, 'learning_rate': 5.012448132780084e-06, 'epoch': 0.2}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d96515322ac48d0a0cb782be92cf63a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10775606334209442, 'eval_f1_score': 0.9789161994247927, 'eval_exact_score': 0.9757796947577969, 'eval_runtime': 142.629, 'eval_samples_per_second': 42.263, 'eval_steps_per_second': 0.337, 'epoch': 0.2}\n",
      "{'loss': 0.1005, 'learning_rate': 7.518672199170125e-06, 'epoch': 0.3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11af4231f790444886f8b908b6f4f053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07987275719642639, 'eval_f1_score': 0.9862370092853056, 'eval_exact_score': 0.9820836098208361, 'eval_runtime': 142.508, 'eval_samples_per_second': 42.299, 'eval_steps_per_second': 0.337, 'epoch': 0.3}\n",
      "{'loss': 0.1176, 'learning_rate': 9.993774642041917e-06, 'epoch': 0.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c5189afb5ab4a2c8106e9839ccdaa71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09616925567388535, 'eval_f1_score': 0.9857208424420072, 'eval_exact_score': 0.9820836098208361, 'eval_runtime': 142.658, 'eval_samples_per_second': 42.255, 'eval_steps_per_second': 0.336, 'epoch': 0.4}\n",
      "{'loss': 0.1049, 'learning_rate': 9.367088607594937e-06, 'epoch': 0.5}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea3dadeb5bb4847958f4d75278199ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06462197750806808, 'eval_f1_score': 0.9848949190882225, 'eval_exact_score': 0.9819177173191772, 'eval_runtime': 142.539, 'eval_samples_per_second': 42.29, 'eval_steps_per_second': 0.337, 'epoch': 0.5}\n",
      "{'loss': 0.099, 'learning_rate': 8.740402573147956e-06, 'epoch': 0.6}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fdacae62f584e45b70c654566eb4b3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06479574739933014, 'eval_f1_score': 0.9877687719718143, 'eval_exact_score': 0.9829130723291307, 'eval_runtime': 142.787, 'eval_samples_per_second': 42.217, 'eval_steps_per_second': 0.336, 'epoch': 0.6}\n",
      "{'loss': 0.0819, 'learning_rate': 8.113716538700976e-06, 'epoch': 0.7}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcaf757753624d04a29d9873c0aaad09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06312631070613861, 'eval_f1_score': 0.9877083787438665, 'eval_exact_score': 0.9854014598540146, 'eval_runtime': 142.749, 'eval_samples_per_second': 42.228, 'eval_steps_per_second': 0.336, 'epoch': 0.7}\n",
      "{'loss': 0.0848, 'learning_rate': 7.487030504253995e-06, 'epoch': 0.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf46e3693254661bbbed7ec1cffbf51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06419671326875687, 'eval_f1_score': 0.9891364647771282, 'eval_exact_score': 0.9873921698739216, 'eval_runtime': 142.651, 'eval_samples_per_second': 42.257, 'eval_steps_per_second': 0.336, 'epoch': 0.8}\n",
      "{'loss': 0.0771, 'learning_rate': 6.8603444698070145e-06, 'epoch': 0.9}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b56a8a43d7554f9dbf09efa99d2feb7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04588242992758751, 'eval_f1_score': 0.9909040588348684, 'eval_exact_score': 0.9890510948905109, 'eval_runtime': 149.828, 'eval_samples_per_second': 40.233, 'eval_steps_per_second': 0.32, 'epoch': 0.9}\n",
      "{'loss': 0.0547, 'learning_rate': 6.233658435360034e-06, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f89f003f0c4be5bd7360dfbb6a92e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04843584820628166, 'eval_f1_score': 0.9916750041920095, 'eval_exact_score': 0.9892169873921699, 'eval_runtime': 147.957, 'eval_samples_per_second': 40.742, 'eval_steps_per_second': 0.324, 'epoch': 1.0}\n",
      "{'loss': 0.0295, 'learning_rate': 5.606972400913053e-06, 'epoch': 1.1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bdc01eb2d5f4668bbe7d9a0926b702d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.05349377542734146, 'eval_f1_score': 0.9917925737556933, 'eval_exact_score': 0.9900464499004645, 'eval_runtime': 149.332, 'eval_samples_per_second': 40.366, 'eval_steps_per_second': 0.321, 'epoch': 1.1}\n",
      "{'loss': 0.0229, 'learning_rate': 4.9802863664660725e-06, 'epoch': 1.2}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1ec4d7ca9543e9a8f0bd73f711dbc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04320317134261131, 'eval_f1_score': 0.9933081898457763, 'eval_exact_score': 0.9915394824153948, 'eval_runtime': 149.41, 'eval_samples_per_second': 40.345, 'eval_steps_per_second': 0.321, 'epoch': 1.2}\n",
      "{'loss': 0.0296, 'learning_rate': 4.353600332019091e-06, 'epoch': 1.3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48fd1c40d76a4a6ebec31b5992aa8e8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03293217346072197, 'eval_f1_score': 0.9945102748022455, 'eval_exact_score': 0.9936960849369608, 'eval_runtime': 149.913, 'eval_samples_per_second': 40.21, 'eval_steps_per_second': 0.32, 'epoch': 1.3}\n",
      "{'loss': 0.0302, 'learning_rate': 3.7269142975721105e-06, 'epoch': 1.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e55b2d77fe4fbeb40ec3def1b0fa4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04069961607456207, 'eval_f1_score': 0.9939959664700349, 'eval_exact_score': 0.9928666224286662, 'eval_runtime': 148.924, 'eval_samples_per_second': 40.477, 'eval_steps_per_second': 0.322, 'epoch': 1.4}\n",
      "{'loss': 0.0377, 'learning_rate': 3.10022826312513e-06, 'epoch': 1.5}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b346e59417964c52aa0766e4a7487181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.028856083750724792, 'eval_f1_score': 0.993830073968376, 'eval_exact_score': 0.9927007299270073, 'eval_runtime': 147.677, 'eval_samples_per_second': 40.819, 'eval_steps_per_second': 0.325, 'epoch': 1.5}\n",
      "{'loss': 0.0208, 'learning_rate': 2.473542228678149e-06, 'epoch': 1.6}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b36d5993304e0c99054e28c2688c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0328320674598217, 'eval_f1_score': 0.992823493822118, 'eval_exact_score': 0.9915394824153948, 'eval_runtime': 147.252, 'eval_samples_per_second': 40.937, 'eval_steps_per_second': 0.326, 'epoch': 1.6}\n",
      "{'loss': 0.0186, 'learning_rate': 1.8468561942311686e-06, 'epoch': 1.7}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcdd4f46a2aa44b58821f4ff65bf4027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.029805831611156464, 'eval_f1_score': 0.9955708392857837, 'eval_exact_score': 0.9945255474452555, 'eval_runtime': 147.997, 'eval_samples_per_second': 40.731, 'eval_steps_per_second': 0.324, 'epoch': 1.7}\n",
      "{'loss': 0.032, 'learning_rate': 1.2201701597841876e-06, 'epoch': 1.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0ea187dbd4945ca8914b9457b9f9b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.02788090892136097, 'eval_f1_score': 0.9956876943812918, 'eval_exact_score': 0.9945255474452555, 'eval_runtime': 147.509, 'eval_samples_per_second': 40.865, 'eval_steps_per_second': 0.325, 'epoch': 1.8}\n",
      "{'loss': 0.0241, 'learning_rate': 5.934841253372069e-07, 'epoch': 1.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d04594cd0f482198ada75d5121329a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.021794382482767105, 'eval_f1_score': 0.9957652792213685, 'eval_exact_score': 0.9946914399469144, 'eval_runtime': 148.116, 'eval_samples_per_second': 40.698, 'eval_steps_per_second': 0.324, 'epoch': 1.91}\n",
      "{'train_runtime': 6428.2526, 'train_samples_per_second': 7.497, 'train_steps_per_second': 0.937, 'train_loss': 0.10857136078564769, 'epoch': 2.0}\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=f\"{'Prueba con ' + str(train_max) if train_max else 'Entrenamiento'}\"):\n",
    "    trainer.train()    \n",
    "    batch_size = trainer._train_batch_size\n",
    "    mlflow.log_param('batch_size',batch_size)\n",
    "    for param_name, param_value in ml_params.items():\n",
    "        mlflow.log_param(param_name, param_value)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.992911696434021,\n",
       " 'start': 81,\n",
       " 'end': 103,\n",
       " 'answer': 'Paquito de los Palotes'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_pipeline = pipeline(\n",
    "    task=\"question-answering\",\n",
    "    model=trainer.model,\n",
    "    # batch_size=64,\n",
    "    tokenizer=tokenizer,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "comprobando = ({'question': \"¿qué notario ha firmado el documento?\", 'context': \"DOS MIL TREINTA. En mi residencia, a quince de abril de dos mil quince. Ante mí, Paquito de los Palotes, notario del ilustre colegio de la Palmilla COMPARECEN Manolito y Jacinta para firmar la siguiente escritura de HERENCIA y para lo cual se sientan cómodamente.\"})\n",
    "\n",
    "tuned_pipeline(comprobando)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../Models/20240213-2010_escrituras_QA_2-epoch_6024-steps\\\\tokenizer_config.json',\n",
       " '../Models/20240213-2010_escrituras_QA_2-epoch_6024-steps\\\\special_tokens_map.json',\n",
       " '../Models/20240213-2010_escrituras_QA_2-epoch_6024-steps\\\\vocab.json',\n",
       " '../Models/20240213-2010_escrituras_QA_2-epoch_6024-steps\\\\merges.txt',\n",
       " '../Models/20240213-2010_escrituras_QA_2-epoch_6024-steps\\\\added_tokens.json',\n",
       " '../Models/20240213-2010_escrituras_QA_2-epoch_6024-steps\\\\tokenizer.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardar el modelo\n",
    "n_epochs = trainer.args.num_train_epochs\n",
    "g_steps = trainer.state.global_step\n",
    "fecha_hora = datetime.datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "ruta_modelo_ajustado = f\"../Models/{fecha_hora}_escrituras_QA_{n_epochs}-epoch_{g_steps}-steps\"\n",
    "trainer.save_model(ruta_modelo_ajustado)\n",
    "tokenizer.save_pretrained(ruta_modelo_ajustado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del modelo generado\n",
    "previo a la evaluación hay que hacer un Restart del entorno en VS Code... el sistema se me queda sin memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/13 20:49:14 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2024/02/13 20:49:14 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of transformers. If you encounter errors during autologging, try upgrading / downgrading transformers to a supported version, or try upgrading MLflow.\n",
      "2024/02/13 20:49:14 INFO mlflow.tracking.fluent: Autologging successfully enabled for transformers.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Incorrect path_or_model_id: '../20240213-2010_escrituras_QA_2-epoch_6024-steps'. Please provide either the path to a local folder or the repo_id of a model on the Hub.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mp:\\Universidad Int de Valencia\\09MIAR_TFM\\Source\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:385\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 385\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mp:\\Universidad Int de Valencia\\09MIAR_TFM\\Source\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:110\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 110\u001b[0m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mp:\\Universidad Int de Valencia\\09MIAR_TFM\\Source\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:164\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[1;34m(repo_id)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must use alphanumeric chars or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m are\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    166\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m forbidden, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m cannot start or end the name, max length is 96:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    168\u001b[0m     )\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id:\n",
      "\u001b[1;31mHFValidationError\u001b[0m: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: '../20240213-2010_escrituras_QA_2-epoch_6024-steps'.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m main_dataset[split_test] \u001b[38;5;66;03m# load_dataset('../Dataset/Escrituras','QA',trust_remote_code=True,split='validation')\u001b[39;00m\n\u001b[0;32m      7\u001b[0m ruta_modelo_ajustado \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../20240213-2010_escrituras_QA_2-epoch_6024-steps\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 8\u001b[0m modelo_ajustado \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForQuestionAnswering\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruta_modelo_ajustado\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m tokenizer_ajustado \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(ruta_modelo_ajustado)\n\u001b[0;32m     10\u001b[0m val_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m\n",
      "File \u001b[1;32mp:\\Universidad Int de Valencia\\09MIAR_TFM\\Source\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:488\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m commit_hash \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[0;32m    487\u001b[0m         \u001b[38;5;66;03m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[39;00m\n\u001b[1;32m--> 488\u001b[0m         resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    495\u001b[0m         commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[0;32m    496\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mp:\\Universidad Int de Valencia\\09MIAR_TFM\\Source\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:450\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere was a specific connection error when trying to load \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HFValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 450\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    451\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect path_or_model_id: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please provide either the path to a local folder or the repo_id of a model on the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    452\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n",
      "\u001b[1;31mOSError\u001b[0m: Incorrect path_or_model_id: '../20240213-2010_escrituras_QA_2-epoch_6024-steps'. Please provide either the path to a local folder or the repo_id of a model on the Hub."
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(SERVIDOR_MLFLOW)\n",
    "mlflow.autolog()\n",
    "mlflow.set_experiment(\"ENTRENAMIENTO Question-Answering\")\n",
    "\n",
    "split_test = 'validation'\n",
    "test_dataset = main_dataset[split_test] # load_dataset('../Dataset/Escrituras','QA',trust_remote_code=True,split='validation')\n",
    "ruta_modelo_ajustado = \"../Models/20240213-2010_escrituras_QA_2-epoch_6024-steps\"\n",
    "modelo_ajustado = AutoModelForQuestionAnswering.from_pretrained(ruta_modelo_ajustado)\n",
    "tokenizer_ajustado = AutoTokenizer.from_pretrained(ruta_modelo_ajustado)\n",
    "val_batch_size = 512\n",
    "\n",
    "with mlflow.start_run(run_name=\"VALIDACIÓN\",description=\"Validación del modelo ajustado\"):\n",
    "    # Definición del pipeline y el conjunto de datos\n",
    "    qc_dataset_test = [{'question':q, 'context':c} for q,c in zip(test_dataset['question'],test_dataset['context'])]\n",
    "    consulta_qc = pipeline(\"question-answering\", model=modelo_ajustado, tokenizer=tokenizer_ajustado, \n",
    "                    device=0 if torch.cuda.is_available() else None, batch_size=val_batch_size)\n",
    "    # Ejecución y cálculo de métricas\n",
    "    predicciones = consulta_qc(qc_dataset_test)\n",
    "    exact_scores, f1_scores  = get_raw_scores_by_prediction(test_dataset,predicciones)\n",
    "    f1_mean = mean(f1_scores.values())\n",
    "    exact_mean = mean(exact_scores.values())\n",
    "    \n",
    "    for param_name, param_value in ml_params.items():\n",
    "        mlflow.log_param(param_name, param_value)\n",
    "    mlflow.log_param('split', split_test)\n",
    "    mlflow.log_metric('f1', f1_mean)\n",
    "    mlflow.log_metric('exact', exact_mean)\n",
    "    print(len(f1_scores), 'f1:', f1_mean)\n",
    "    print(len(exact_scores), 'exact:', exact_mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

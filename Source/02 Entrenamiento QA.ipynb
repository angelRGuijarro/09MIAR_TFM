{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from metrics.evaluate import compute_exact, compute_f1\n",
    "from metrics.evaluar_metricas import evaluar_metricas_QA\n",
    "import mlflow\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, Trainer, TrainingArguments, pipeline\n",
    "import requests\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pprint\n",
    "# Impresión elegante de datos en la terminal\n",
    "pp = pprint.PrettyPrinter(width=150)\n",
    "from tqdm import tqdm\n",
    "from globals import TRAINING_DIR,MODELS_DIR, DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definición de variables globales, parámetros de entrenamiento y MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLES GLOBALES\n",
    "train_max = None # Número máximo de elementos para entrenamiento (para pruebas) None para ir en serio\n",
    "training_output_dir = os.path.join(TRAINING_DIR,\"QA\")\n",
    "# Defino una serie de variables que registraré en los entrenamientos de MLflow\n",
    "ml_params = {\n",
    "    'num_epochs': 2,\n",
    "    'lr' : 1e-5,\n",
    "    'eval_steps' : 0.05, \n",
    "    'eval_batch_size' : 64,\n",
    "    'model_name': os.path.join(MODELS_DIR,'PlanTL-GOB-ES','roberta-large-bne-sqac')\n",
    "}\n",
    "num_epochs = lr = eval_steps = eval_batch_size = model_name = 0\n",
    "for key, value in ml_params.items():\n",
    "    assert not globals()[key] is None, f'La variable global {key} debe estar definida'    \n",
    "    globals()[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga del conjunto de datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dataset = load_dataset(os.path.join(DATA_DIR,'Escrituras'), 'QA', trust_remote_code=True)\n",
    "train_dataset = main_dataset['train']\n",
    "val_dataset = main_dataset['validation']\n",
    "if train_max:\n",
    "    train_dataset = train_dataset.select(range(train_max))\n",
    "    val_dataset = val_dataset.select(range(train_max))\n",
    "del main_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobación de que el servidor MLflow está funcionando para las pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVIDOR_MLFLOW = 'http://localhost:5000'\n",
    "# Debo comprobar si está ejecutando el servidor MLflow, en otro caso se demora la ejecución y acaba dando un error\n",
    "def mlflow_en_ejecucion(url):\n",
    "    try:\n",
    "        response = requests.get(url)        \n",
    "        # Si el servidor está en ejecución, deberíamos recibir un código de estado HTTP 200\n",
    "        return response.status_code == 200\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        # Si no se puede establecer una conexión, asumimos que el servidor no está en ejecución\n",
    "        return False\n",
    "    \n",
    "assert mlflow_en_ejecucion(SERVIDOR_MLFLOW), f\"El servidor MLflow ({SERVIDOR_MLFLOW}) no está en ejecución. Lance 'mlflow ui' desde el terminal.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iniciamos el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/19 00:20:37 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2024/02/19 00:20:37 INFO mlflow.tracking.fluent: Autologging successfully enabled for transformers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/469736907013971428', creation_time=1708261517045, experiment_id='469736907013971428', last_update_time=1708261517045, lifecycle_stage='active', name='02 ENTRENAMIENTO Question-Answering', tags={}>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Servidor de seguimiento\n",
    "mlflow.set_tracking_uri(SERVIDOR_MLFLOW)\n",
    "mlflow.autolog()\n",
    "mlflow.set_experiment(\"02 ENTRENAMIENTO Question-Answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extraído del tuturial en HF sobre Question-Answering\n",
    "def f_preproceso(examples):\n",
    "    \"\"\"Función para generar los input_ids, atention_mask y otras características para el entrenamiento\"\"\"\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=512,\n",
    "        stride=128,\n",
    "        truncation=\"only_second\",\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    labels = []\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        answer = answers[i]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        # la secuencia indica qué tokens son de pregunta y cuales de contexto\n",
    "        sequence_ids = inputs.sequence_ids(i) \n",
    "\n",
    "        # Busca el inicio y el final del contexto\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # Si la pregunta no está íntegra en el contexto etiquetamos con (0,0)\n",
    "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "            labels.append([0,0])\n",
    "        else:\n",
    "            # En otro caso, se encuentra entre los tokens de inicio y final\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start = idx - 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end =idx + 1\n",
    "            end_positions.append(idx + 1)\n",
    "            labels.append([start,end])\n",
    "        \n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    inputs[\"labels\"] = labels \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized = train_dataset.map(f_preproceso,batched=True, remove_columns=train_dataset.column_names)\n",
    "eval_tokenized = val_dataset.map(f_preproceso,batched=True, remove_columns=val_dataset.column_names)\n",
    "del train_dataset\n",
    "del val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetInfo(description='',\n",
      "            citation='',\n",
      "            homepage='',\n",
      "            license='',\n",
      "            features={'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
      "                      'end_positions': Value(dtype='int64', id=None),\n",
      "                      'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
      "                      'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
      "                      'start_positions': Value(dtype='int64', id=None)},\n",
      "            post_processed=None,\n",
      "            supervised_keys=None,\n",
      "            task_templates=None,\n",
      "            builder_name='escrituras',\n",
      "            dataset_name='escrituras',\n",
      "            config_name='QA',\n",
      "            version=0.0.0,\n",
      "            splits={'test': SplitInfo(name='test', num_bytes=11002385, num_examples=7532, shard_lengths=None, dataset_name='escrituras'),\n",
      "                    'train': SplitInfo(name='train', num_bytes=35013784, num_examples=24096, shard_lengths=None, dataset_name='escrituras'),\n",
      "                    'validation': SplitInfo(name='validation', num_bytes=8786051, num_examples=6028, shard_lengths=None, dataset_name='escrituras')},\n",
      "            download_checksums={'QA_test.json': {'checksum': None, 'num_bytes': 3590989},\n",
      "                                'QA_train.json': {'checksum': None, 'num_bytes': 11427604},\n",
      "                                'QA_validation.json': {'checksum': None, 'num_bytes': 2866185}},\n",
      "            download_size=17884778,\n",
      "            post_processing_size=None,\n",
      "            dataset_size=54802220,\n",
      "            size_in_bytes=72686998)\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(train_tokenized.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    pred_ini = np.argmax(eval_pred.predictions[0],axis=1)\n",
    "    pred_fin = np.argmax(eval_pred.predictions[1],axis=1)\n",
    "    pred_txt = [tokenizer.decode(tokens[p_ini:p_fin+1]).strip() for tokens,p_ini,p_fin in zip(eval_pred.inputs,pred_ini,pred_fin)]\n",
    "    \n",
    "    gold_ini = eval_pred.label_ids[0]\n",
    "    gold_fin = eval_pred.label_ids[1]\n",
    "    gold_txt = [tokenizer.decode(tokens[g_ini:g_fin+1]).strip() for tokens,g_ini,g_fin in zip(eval_pred.inputs,gold_ini,gold_fin)]\n",
    "    \n",
    "    f1s = [compute_f1(g,p) for g,p in zip(gold_txt,pred_txt)]\n",
    "    ems = [compute_exact(g,p) for g,p in zip(gold_txt,pred_txt)]\n",
    "\n",
    "    return {'f1_score':np.mean(f1s), 'exact_score': np.mean(ems)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arg = TrainingArguments(\n",
    "    output_dir=training_output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    do_train=True,\n",
    "    learning_rate=lr,\n",
    "    warmup_ratio=0.2,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=eval_steps,\n",
    "    save_strategy='steps',\n",
    "    save_steps=eval_steps,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1_score',\n",
    "    logging_steps=eval_steps,\n",
    "    auto_find_batch_size=True,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    include_inputs_for_metrics=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_arg,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=eval_tokenized,    \n",
    "    tokenizer=tokenizer,    \n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bf4acf2cde5422a9b4c186c5771ad52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0132, 'learning_rate': 2.506224066390042e-06, 'epoch': 0.1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db08943a4b28431ab637e975c433fa47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ..\\training\\QA\\checkpoint-302 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2236010730266571, 'eval_f1_score': 0.9546375879610878, 'eval_exact_score': 0.942601194426012, 'eval_runtime': 141.164, 'eval_samples_per_second': 42.702, 'eval_steps_per_second': 0.673, 'epoch': 0.1}\n",
      "{'loss': 0.1321, 'learning_rate': 5.012448132780084e-06, 'epoch': 0.2}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb344570bb14f35ab67189057d4f8ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12046411633491516, 'eval_f1_score': 0.9686049579744994, 'eval_exact_score': 0.966821499668215, 'eval_runtime': 141.251, 'eval_samples_per_second': 42.676, 'eval_steps_per_second': 0.673, 'epoch': 0.2}\n",
      "{'loss': 0.1097, 'learning_rate': 7.518672199170125e-06, 'epoch': 0.3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dccbbfcad66a4d0686a132b0c3b79ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10524611175060272, 'eval_f1_score': 0.9811953203604471, 'eval_exact_score': 0.9781021897810219, 'eval_runtime': 141.449, 'eval_samples_per_second': 42.616, 'eval_steps_per_second': 0.672, 'epoch': 0.3}\n",
      "{'loss': 0.0774, 'learning_rate': 9.993774642041917e-06, 'epoch': 0.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c9d4158a6c84199bcc880e271631be5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1250726729631424, 'eval_f1_score': 0.9739426979428766, 'eval_exact_score': 0.9698075646980756, 'eval_runtime': 141.447, 'eval_samples_per_second': 42.617, 'eval_steps_per_second': 0.672, 'epoch': 0.4}\n",
      "{'loss': 0.1118, 'learning_rate': 9.367088607594937e-06, 'epoch': 0.5}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfca1a0ad296451ca4b651228c7651b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07257575541734695, 'eval_f1_score': 0.9793948972080436, 'eval_exact_score': 0.9774386197743862, 'eval_runtime': 141.556, 'eval_samples_per_second': 42.584, 'eval_steps_per_second': 0.671, 'epoch': 0.5}\n",
      "{'loss': 0.0405, 'learning_rate': 8.740402573147956e-06, 'epoch': 0.6}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58323fc32d76470dbcdb5adca4d182f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08856762200593948, 'eval_f1_score': 0.988843183247588, 'eval_exact_score': 0.9854014598540146, 'eval_runtime': 141.576, 'eval_samples_per_second': 42.578, 'eval_steps_per_second': 0.671, 'epoch': 0.6}\n",
      "{'loss': 0.0473, 'learning_rate': 8.113716538700976e-06, 'epoch': 0.7}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0860a2dbdd2b48dd8fac94044a3c79d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08544055372476578, 'eval_f1_score': 0.9869060164353542, 'eval_exact_score': 0.9850696748506967, 'eval_runtime': 141.333, 'eval_samples_per_second': 42.651, 'eval_steps_per_second': 0.672, 'epoch': 0.7}\n",
      "{'loss': 0.0629, 'learning_rate': 7.487030504253995e-06, 'epoch': 0.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9889d52142b24bfb983575ed1bebeede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06621473282575607, 'eval_f1_score': 0.9881833381329653, 'eval_exact_score': 0.9858991373589914, 'eval_runtime': 141.314, 'eval_samples_per_second': 42.657, 'eval_steps_per_second': 0.672, 'epoch': 0.8}\n",
      "{'loss': 0.0693, 'learning_rate': 6.8603444698070145e-06, 'epoch': 0.9}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "607b7686bd144ed899679552f0158296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06027235463261604, 'eval_f1_score': 0.9896903907617908, 'eval_exact_score': 0.9883875248838753, 'eval_runtime': 141.278, 'eval_samples_per_second': 42.668, 'eval_steps_per_second': 0.672, 'epoch': 0.9}\n",
      "{'loss': 0.0277, 'learning_rate': 6.233658435360034e-06, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e38cb00183c4f9fac7455e554774d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.05897032469511032, 'eval_f1_score': 0.9899613196307058, 'eval_exact_score': 0.988885202388852, 'eval_runtime': 141.241, 'eval_samples_per_second': 42.679, 'eval_steps_per_second': 0.673, 'epoch': 1.0}\n",
      "{'loss': 0.0179, 'learning_rate': 5.606972400913053e-06, 'epoch': 1.1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac17d75c9f4481884f25dc6086456ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0520549900829792, 'eval_f1_score': 0.9923955156050476, 'eval_exact_score': 0.9918712674187127, 'eval_runtime': 141.359, 'eval_samples_per_second': 42.643, 'eval_steps_per_second': 0.672, 'epoch': 1.1}\n",
      "{'loss': 0.0203, 'learning_rate': 4.9802863664660725e-06, 'epoch': 1.2}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "862d308e16b64cf28a32021814f978da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03773544728755951, 'eval_f1_score': 0.9936564812151959, 'eval_exact_score': 0.9927007299270073, 'eval_runtime': 141.186, 'eval_samples_per_second': 42.695, 'eval_steps_per_second': 0.673, 'epoch': 1.2}\n",
      "{'loss': 0.0205, 'learning_rate': 4.353600332019091e-06, 'epoch': 1.3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a26091113f4a09ae54c6ef6db594df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.05073569715023041, 'eval_f1_score': 0.992079740544747, 'eval_exact_score': 0.9903782349037823, 'eval_runtime': 141.118, 'eval_samples_per_second': 42.716, 'eval_steps_per_second': 0.673, 'epoch': 1.3}\n",
      "{'loss': 0.0235, 'learning_rate': 3.7269142975721105e-06, 'epoch': 1.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "341a25ccfa6e4d9eafcb8d60e5e6e456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.038729164749383926, 'eval_f1_score': 0.9935578648777007, 'eval_exact_score': 0.9925348374253484, 'eval_runtime': 141.062, 'eval_samples_per_second': 42.733, 'eval_steps_per_second': 0.673, 'epoch': 1.4}\n",
      "{'loss': 0.0115, 'learning_rate': 3.10022826312513e-06, 'epoch': 1.5}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1bbb950af4f4fbab1c28b95397f1452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.029656022787094116, 'eval_f1_score': 0.9949539355434138, 'eval_exact_score': 0.9943596549435966, 'eval_runtime': 141.244, 'eval_samples_per_second': 42.678, 'eval_steps_per_second': 0.673, 'epoch': 1.5}\n",
      "{'loss': 0.0114, 'learning_rate': 2.473542228678149e-06, 'epoch': 1.6}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd25e0e710eb470da9d448209f18722e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03464436158537865, 'eval_f1_score': 0.9942903655367781, 'eval_exact_score': 0.9936960849369608, 'eval_runtime': 141.283, 'eval_samples_per_second': 42.666, 'eval_steps_per_second': 0.672, 'epoch': 1.6}\n",
      "{'loss': 0.02, 'learning_rate': 1.8468561942311686e-06, 'epoch': 1.7}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8622c5c6f98b481284f0904e865c6785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.029813602566719055, 'eval_f1_score': 0.9951663943613278, 'eval_exact_score': 0.9943596549435966, 'eval_runtime': 141.311, 'eval_samples_per_second': 42.658, 'eval_steps_per_second': 0.672, 'epoch': 1.7}\n",
      "{'loss': 0.0096, 'learning_rate': 1.2201701597841876e-06, 'epoch': 1.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07dbf3e3fa9b4f4d87c0478f9c9a87d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03482209891080856, 'eval_f1_score': 0.9945945017898195, 'eval_exact_score': 0.9938619774386198, 'eval_runtime': 141.397, 'eval_samples_per_second': 42.632, 'eval_steps_per_second': 0.672, 'epoch': 1.8}\n",
      "{'loss': 0.0077, 'learning_rate': 5.934841253372069e-07, 'epoch': 1.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ad91d7f219d464aa4d71d719c982568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.029949210584163666, 'eval_f1_score': 0.9956087743657517, 'eval_exact_score': 0.9950232249502322, 'eval_runtime': 144.119, 'eval_samples_per_second': 41.827, 'eval_steps_per_second': 0.659, 'epoch': 1.91}\n",
      "{'train_runtime': 6284.563, 'train_samples_per_second': 7.668, 'train_steps_per_second': 0.959, 'train_loss': 0.0920549368320075, 'epoch': 2.0}\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=f\"{'Prueba con ' + str(train_max) if train_max else 'Entrenamiento'}\"):\n",
    "    trainer.train()    \n",
    "    for param_name, param_value in ml_params.items():\n",
    "        mlflow.log_param(param_name, param_value)    \n",
    "    \n",
    "    # Guardar el modelo\n",
    "    n_epochs = trainer.args.num_train_epochs\n",
    "    g_steps = trainer.state.global_step\n",
    "    fecha_hora = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "    ruta_modelo_ajustado = os.path.join(MODELS_DIR,f\"{fecha_hora}_escrituras_QA_{n_epochs}-epoch_{g_steps}-steps\")\n",
    "    trainer.save_model(ruta_modelo_ajustado)\n",
    "    tokenizer.save_pretrained(ruta_modelo_ajustado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una comprobación de que el modelo está respondiendo a las preguntas correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9999687671661377, 'start': 81, 'end': 103, 'answer': 'Paquito de los Palotes'}\n",
      "{'score': 0.9892922043800354, 'start': 0, 'end': 15, 'answer': 'DOS MIL TREINTA'}\n"
     ]
    }
   ],
   "source": [
    "tuned_pipeline = pipeline(\n",
    "    task=\"question-answering\",\n",
    "    model=trainer.model,\n",
    "    tokenizer=tokenizer,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "comprobando = ({'question': \"¿qué notario ha firmado el documento?\", 'context': \"DOS MIL TREINTA. En mi residencia, a quince de abril de dos mil quince. Ante mí, Paquito de los Palotes, notario del ilustre colegio de la Palmilla COMPARECEN Manolito y Jacinta para firmar la siguiente escritura de HERENCIA y para lo cual se sientan cómodamente.\"})\n",
    "print(tuned_pipeline(comprobando))\n",
    "\n",
    "comprobando = ({'question': \"¿cuál es el número de protocolo?\", 'context': \"DOS MIL TREINTA. En mi residencia, a quince de abril de dos mil quince. Ante mí, Paquito de los Palotes, notario del ilustre colegio de la Palmilla COMPARECEN Manolito y Jacinta para firmar la siguiente escritura de HERENCIA y para lo cual se sientan cómodamente.\"})\n",
    "print(tuned_pipeline(comprobando))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del modelo generado\n",
    "previo a la evaluación hay que hacer un Restart del entorno en VS Code... el sistema se me queda sin memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from metrics.evaluar_metricas import evaluar_metricas_QA\n",
    "import mlflow\n",
    "import requests\n",
    "import os\n",
    "from globals import MODELS_DIR, DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVIDOR_MLFLOW = 'http://localhost:5000'\n",
    "# Debo comprobar si está ejecutando el servidor MLflow, en otro caso se demora la ejecución y acaba dando un error\n",
    "def mlflow_en_ejecucion(url):\n",
    "    try:\n",
    "        response = requests.get(url)        \n",
    "        # Si el servidor está en ejecución, deberíamos recibir un código de estado HTTP 200\n",
    "        return response.status_code == 200\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        # Si no se puede establecer una conexión, asumimos que el servidor no está en ejecución\n",
    "        return False\n",
    "    \n",
    "assert mlflow_en_ejecucion(SERVIDOR_MLFLOW), f\"El servidor MLflow ({SERVIDOR_MLFLOW}) no está en ejecución. Lance 'mlflow ui' desde el terminal.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/19 02:16:05 INFO mlflow.tracking.fluent: Autologging successfully enabled for transformers.\n",
      "2024/02/19 02:16:06 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\Models\\..\\Models\\20240219-0205_escrituras_QA_2-epoch_6024-steps\n",
      "\tf1: 0.9691215891561086\n",
      "\texact: 0.9676048858204992\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(SERVIDOR_MLFLOW)\n",
    "mlflow.autolog()\n",
    "mlflow.set_experiment(\"02 ENTRENAMIENTO Question-Answering\")\n",
    "\n",
    "split_test = 'test'\n",
    "test_dataset = load_dataset(os.path.join(DATA_DIR,'Escrituras'),'QA',trust_remote_code=True,split='test')\n",
    "# Copiar la ruta del último modelo ajustado\n",
    "ruta_modelo_ajustado = os.path.join(MODELS_DIR,os.path.join(MODELS_DIR,'20240219-0205_escrituras_QA_2-epoch_6024-steps'))\n",
    "\n",
    "with mlflow.start_run(run_name=\"VALIDACIÓN\",description=\"Validación del modelo QA ajustado\"):\n",
    "    evaluar_metricas_QA(ruta_modelo_ajustado, test_dataset)    \n",
    "    \n",
    "\n",
    "# for ruta in tqdm([r for r in os.listdir(MODELS_DIR) if os.path.isdir(MODELS_DIR+r)]):\n",
    "#     if \"escrituras_QA\" in ruta:\n",
    "#         ruta_modelo_ajustado = os.path.join(MODELS_DIR,ruta)\n",
    "#         with mlflow.start_run(run_name=\"VALIDACIÓN\",description=\"Validación del modelo ajustado\"):\n",
    "#             evaluar_metricas_QA(ruta_modelo_ajustado, test_dataset)            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

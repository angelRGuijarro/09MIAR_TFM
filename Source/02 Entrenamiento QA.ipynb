{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "# from custom_evaluate import get_raw_scores, compute_exact, compute_f1 #get_raw_scores_by_prediction\n",
    "# import evaluate\n",
    "from statistics import mean\n",
    "import mlflow\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, Trainer, TrainingArguments, \\\n",
    "    pipeline, DataCollatorWithPadding, EarlyStoppingCallback\n",
    "import requests\n",
    "import torch\n",
    "import numpy as np\n",
    "import os, shutil\n",
    "from datetime import datetime\n",
    "import pprint\n",
    "# Impresión elegante de datos en la terminal\n",
    "pp = pprint.PrettyPrinter(width=150)\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from metrics.evaluate import (\n",
    "    get_raw_scores,\n",
    "    compute_f1,\n",
    "    compute_exact\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLES GLOBALES\n",
    "train_max = None # Número máximo de elementos para entrenamiento (para pruebas) None para ir en serio\n",
    "training_output_dir = \"../training/QA\"\n",
    "ml_params = {\n",
    "    'num_epochs': 3,\n",
    "    # 'batch_size': 8, \n",
    "    'lr' : 5e-5,\n",
    "    'eval_steps' : 0.05, \n",
    "    'eval_batch_size' : 64,\n",
    "    'model_name': '../Models/PlanTL-GOB-ES/roberta-large-bne-sqac' \n",
    "}\n",
    "num_epochs = lr = eval_steps = eval_batch_size = model_name = 0\n",
    "for key, value in ml_params.items():\n",
    "    assert not globals()[key] is None, f'La variable global {key} debe estar definida'    \n",
    "    globals()[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dataset = load_dataset('../Dataset/Escrituras', 'QA', trust_remote_code=True)\n",
    "train_dataset = main_dataset['train']\n",
    "val_dataset = main_dataset['validation']\n",
    "if train_max:\n",
    "    train_dataset = train_dataset.select(range(train_max))\n",
    "    val_dataset = val_dataset.select(range(train_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVIDOR_MLFLOW = 'http://localhost:5000'\n",
    "# Debo comprobar si está ejecutando el servidor MLflow, en otro caso se demora la ejecución y acaba dando un error\n",
    "def mlflow_en_ejecucion(url):\n",
    "    try:\n",
    "        response = requests.get(url)        \n",
    "        # Si el servidor está en ejecución, deberíamos recibir un código de estado HTTP 200\n",
    "        return response.status_code == 200\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        # Si no se puede establecer una conexión, asumimos que el servidor no está en ejecución\n",
    "        return False\n",
    "    \n",
    "assert mlflow_en_ejecucion(SERVIDOR_MLFLOW), f\"El servidor MLflow ({SERVIDOR_MLFLOW}) no está en ejecución. Lance 'mlflow ui' desde el terminal.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/15 00:13:29 INFO mlflow.tracking.fluent: Autologging successfully enabled for transformers.\n",
      "2024/02/15 00:13:30 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/423598931169215837', creation_time=1707602045463, experiment_id='423598931169215837', last_update_time=1707602045463, lifecycle_stage='active', name='ENTRENAMIENTO Question-Answering', tags={}>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Servidor de seguimiento\n",
    "mlflow.set_tracking_uri(SERVIDOR_MLFLOW)\n",
    "mlflow.autolog()\n",
    "mlflow.set_experiment(\"ENTRENAMIENTO Question-Answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extraído del tuturial en HF sobre Question-Answering\n",
    "def f_preproceso(examples):\n",
    "    question = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        question,\n",
    "        examples[\"context\"],\n",
    "        max_length=512,\n",
    "        stride=128,\n",
    "        truncation=\"only_second\",\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # Posiciones de los caracteres que representa cada token\n",
    "    # offset_mapping tiene una lista de offsets por cada ejemplo\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    # Y answers una lista de respuestas para cada pregunta\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    labels = []\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        answer = answers[i]\n",
    "        #sólo se considera una respuesta\n",
    "        start_char = answer[\"answer_start\"][0] \n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        # la secuencia indica qué tokens son de pregunta y cuales de contexto\n",
    "        sequence_ids = inputs.sequence_ids(i) \n",
    "\n",
    "        # Busca el inicio y el final del contexto\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # Si la pregunta no está íntegra en el contexto etiquetamos con (0,0)\n",
    "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "            labels.append([0,0])\n",
    "        else:\n",
    "            # En otro caso, se encuentra entre los tokens de inicio y final\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start = idx - 1\n",
    "            start_positions.append(start)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end = idx + 1\n",
    "            end_positions.append(end)\n",
    "            labels.append([start,end])\n",
    "        \n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    inputs[\"labels\"] = labels \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized = train_dataset.map(f_preproceso,batched=True, remove_columns=train_dataset.column_names)\n",
    "eval_tokenized = val_dataset.map(f_preproceso,batched=True, remove_columns=val_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetInfo(description='',\n",
      "            citation='',\n",
      "            homepage='',\n",
      "            license='',\n",
      "            features={'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
      "                      'end_positions': Value(dtype='int64', id=None),\n",
      "                      'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
      "                      'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
      "                      'start_positions': Value(dtype='int64', id=None)},\n",
      "            post_processed=None,\n",
      "            supervised_keys=None,\n",
      "            task_templates=None,\n",
      "            builder_name='escrituras',\n",
      "            dataset_name='escrituras',\n",
      "            config_name='QA',\n",
      "            version=0.0.0,\n",
      "            splits={'test': SplitInfo(name='test', num_bytes=11002385, num_examples=7532, shard_lengths=None, dataset_name='escrituras'),\n",
      "                    'train': SplitInfo(name='train', num_bytes=35013784, num_examples=24096, shard_lengths=None, dataset_name='escrituras'),\n",
      "                    'validation': SplitInfo(name='validation', num_bytes=8786051, num_examples=6028, shard_lengths=None, dataset_name='escrituras')},\n",
      "            download_checksums={'QA_test.json': {'checksum': None, 'num_bytes': 3590989},\n",
      "                                'QA_train.json': {'checksum': None, 'num_bytes': 11427604},\n",
      "                                'QA_validation.json': {'checksum': None, 'num_bytes': 2866185}},\n",
      "            download_size=17884778,\n",
      "            post_processing_size=None,\n",
      "            dataset_size=54802220,\n",
      "            size_in_bytes=72686998)\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(train_tokenized.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "# metric = evaluate.load('squad_v2')\n",
    "     \n",
    "def compute_metrics(eval_pred):\n",
    "    pred_ini = np.argmax(eval_pred.predictions[0],axis=1)\n",
    "    pred_fin = np.argmax(eval_pred.predictions[1],axis=1)\n",
    "    pred_txt = [tokenizer.decode(tokens[p_ini:p_fin+1]).strip() for tokens,p_ini,p_fin in zip(eval_pred.inputs,pred_ini,pred_fin)]\n",
    "    \n",
    "    gold_ini = eval_pred.label_ids[0] # token inicial si hubiera más de una respuesta, se consideraría una lista\n",
    "    gold_fin = eval_pred.label_ids[1] # token final\n",
    "    gold_txt = [tokenizer.decode(tokens[g_ini:g_fin+1]).strip() for tokens,g_ini,g_fin in zip(eval_pred.inputs,gold_ini,gold_fin)]\n",
    "    \n",
    "    f1s = [compute_f1(g,p) for g,p in zip(gold_txt,pred_txt)]\n",
    "    ems = [compute_exact(g,p) for g,p in zip(gold_txt,pred_txt)]    \n",
    "\n",
    "    # return metric.compute(predictions=eval_pred.predictions, references=eval_pred.label_ids)\n",
    "    return {'f1_score':np.mean(f1s), 'exact_score': np.mean(ems)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrar el directorio de entrenamiento si existe\n",
    "# if os.path.exists(training_output_dir):\n",
    "#     shutil.rmtree(training_output_dir)\n",
    "\n",
    "training_arg = TrainingArguments(\n",
    "    output_dir=training_output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    do_train=True,\n",
    "    learning_rate=lr,\n",
    "    warmup_ratio=0.2,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=eval_steps,\n",
    "    save_strategy='steps',\n",
    "    save_steps=eval_steps,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='eval_loss', # greater_is_better=False\n",
    "    greater_is_better=False,\n",
    "    logging_steps=eval_steps,\n",
    "    # per_device_train_batch_size=batch_size,\n",
    "    auto_find_batch_size=True,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    include_inputs_for_metrics=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_arg,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=eval_tokenized,    \n",
    "    tokenizer=tokenizer,    \n",
    "    compute_metrics=compute_metrics\n",
    "    # ,\n",
    "    # callbacks=[EarlyStoppingCallback(5,1e-4)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaff2e18554f42ec8a3a15ac666c4b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9036 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1033, 'learning_rate': 1.25e-05, 'epoch': 0.15}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69019277b31e4038a98cb92e2a1b2107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ../training/QA\\checkpoint-452 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12210901081562042, 'eval_f1_score': 0.9825615587510601, 'eval_exact_score': 0.9795952222959522, 'eval_runtime': 148.157, 'eval_samples_per_second': 40.687, 'eval_steps_per_second': 0.641, 'epoch': 0.15}\n",
      "{'loss': 0.131, 'learning_rate': 2.5e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5cccbd26b3d452fb06c72f8746e7b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.24429607391357422, 'eval_f1_score': 0.9590440396349825, 'eval_exact_score': 0.9494027869940279, 'eval_runtime': 143.77, 'eval_samples_per_second': 41.928, 'eval_steps_per_second': 0.661, 'epoch': 0.3}\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '../training/QA\\\\checkpoint-904'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mstart_run(run_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrueba con \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mstr\u001b[39m(train_max)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mtrain_max\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntrenamiento\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[0;32m      3\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39m_train_batch_size\n\u001b[0;32m      4\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mlog_param(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m,batch_size)\n",
      "File \u001b[1;32mp:\\Universidad Int de Valencia\\09MIAR_TFM\\Source\\.venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:578\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    576\u001b[0m     patch_function\u001b[38;5;241m.\u001b[39mcall(call_original, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 578\u001b[0m     \u001b[43mpatch_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall_original\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    580\u001b[0m session\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msucceeded\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    582\u001b[0m try_log_autologging_event(\n\u001b[0;32m    583\u001b[0m     AutologgingEventLogger\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39mlog_patch_function_success,\n\u001b[0;32m    584\u001b[0m     session,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    588\u001b[0m     kwargs,\n\u001b[0;32m    589\u001b[0m )\n",
      "File \u001b[1;32mp:\\Universidad Int de Valencia\\09MIAR_TFM\\Source\\.venv\\Lib\\site-packages\\mlflow\\transformers\\__init__.py:3038\u001b[0m, in \u001b[0;36mautolog.<locals>.train\u001b[1;34m(original, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(original, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   3037\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m disable_discrete_autologging(DISABLED_ANCILLARY_FLAVOR_AUTOLOGGING):\n\u001b[1;32m-> 3038\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moriginal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mp:\\Universidad Int de Valencia\\09MIAR_TFM\\Source\\.venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:559\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001b[1;34m(*og_args, **og_kwargs)\u001b[0m\n\u001b[0;32m    556\u001b[0m         original_result \u001b[38;5;241m=\u001b[39m original(\u001b[38;5;241m*\u001b[39m_og_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_og_kwargs)\n\u001b[0;32m    557\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n\u001b[1;32m--> 559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_original_fn_with_event_logging\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_original_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mog_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mog_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mp:\\Universidad Int de Valencia\\09MIAR_TFM\\Source\\.venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:494\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001b[1;34m(original_fn, og_args, og_kwargs)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    486\u001b[0m     try_log_autologging_event(\n\u001b[0;32m    487\u001b[0m         AutologgingEventLogger\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39mlog_original_function_start,\n\u001b[0;32m    488\u001b[0m         session,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    492\u001b[0m         og_kwargs,\n\u001b[0;32m    493\u001b[0m     )\n\u001b[1;32m--> 494\u001b[0m     original_fn_result \u001b[38;5;241m=\u001b[39m \u001b[43moriginal_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mog_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mog_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    496\u001b[0m     try_log_autologging_event(\n\u001b[0;32m    497\u001b[0m         AutologgingEventLogger\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39mlog_original_function_success,\n\u001b[0;32m    498\u001b[0m         session,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    502\u001b[0m         og_kwargs,\n\u001b[0;32m    503\u001b[0m     )\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m original_fn_result\n",
      "File \u001b[1;32mp:\\Universidad Int de Valencia\\09MIAR_TFM\\Source\\.venv\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:556\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001b[1;34m(*_og_args, **_og_kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[38;5;66;03m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001b[39;00m\n\u001b[0;32m    549\u001b[0m \u001b[38;5;66;03m# during original function execution, even if silent mode is enabled\u001b[39;00m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;66;03m# (`silent=True`), since these warnings originate from the ML framework\u001b[39;00m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;66;03m# or one of its dependencies and are likely relevant to the caller\u001b[39;00m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_non_mlflow_warnings_behavior_for_current_thread(\n\u001b[0;32m    553\u001b[0m     disable_warnings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    554\u001b[0m     reroute_warnings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    555\u001b[0m ):\n\u001b[1;32m--> 556\u001b[0m     original_result \u001b[38;5;241m=\u001b[39m \u001b[43moriginal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_og_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_og_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n",
      "File \u001b[1;32mp:\\Universidad Int de Valencia\\09MIAR_TFM\\Source\\.venv\\Lib\\site-packages\\transformers\\trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1537\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1544\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mp:\\Universidad Int de Valencia\\09MIAR_TFM\\Source\\.venv\\Lib\\site-packages\\accelerate\\utils\\memory.py:136\u001b[0m, in \u001b[0;36mfind_executable_batch_size.<locals>.decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo executable batch size found, reached zero.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_reduce_batch_size(e):\n",
      "File \u001b[1;32mp:\\Universidad Int de Valencia\\09MIAR_TFM\\Source\\.venv\\Lib\\site-packages\\transformers\\trainer.py:1929\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1926\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m-> 1929\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1930\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1931\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[1;32mp:\\Universidad Int de Valencia\\09MIAR_TFM\\Source\\.venv\\Lib\\site-packages\\transformers\\trainer.py:2300\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[1;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2297\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mstep(metrics[metric_to_check])\n\u001b[0;32m   2299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[1;32m-> 2300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2301\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_save(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[1;32mp:\\Universidad Int de Valencia\\09MIAR_TFM\\Source\\.venv\\Lib\\site-packages\\transformers\\trainer.py:2418\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[1;34m(self, model, trial, metrics)\u001b[0m\n\u001b[0;32m   2415\u001b[0m os\u001b[38;5;241m.\u001b[39mrename(staging_output_dir, output_dir)\n\u001b[0;32m   2417\u001b[0m \u001b[38;5;66;03m# Ensure rename completed in cases where os.rename is not atomic\u001b[39;00m\n\u001b[1;32m-> 2418\u001b[0m fd \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mO_RDONLY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2419\u001b[0m os\u001b[38;5;241m.\u001b[39mfsync(fd)\n\u001b[0;32m   2420\u001b[0m os\u001b[38;5;241m.\u001b[39mclose(fd)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '../training/QA\\\\checkpoint-904'"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=f\"{'Prueba con ' + str(train_max) if train_max else 'Entrenamiento'}\"):\n",
    "    trainer.train()    \n",
    "    \n",
    "    batch_size = trainer._train_batch_size\n",
    "    mlflow.log_param('batch_size',batch_size)\n",
    "    for param_name, param_value in ml_params.items():\n",
    "        mlflow.log_param(param_name, param_value)    \n",
    "    # Guardar el modelo\n",
    "    n_epochs = trainer.args.num_train_epochs\n",
    "    g_steps = trainer.state.global_step\n",
    "    fecha_hora = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "    ruta_modelo_ajustado = f\"../Models/{fecha_hora}_escrituras_QA_{n_epochs}-epoch_{g_steps}-steps\"\n",
    "    mlflow.log_param('finetuned_name', os.path.basename(ruta_modelo_ajustado))\n",
    "    trainer.save_model(ruta_modelo_ajustado)\n",
    "    tokenizer.save_pretrained(ruta_modelo_ajustado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_pipeline = pipeline(\n",
    "    task=\"question-answering\",\n",
    "    model=trainer.model,\n",
    "    # batch_size=64,\n",
    "    tokenizer=tokenizer,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "comprobando = ({'question': \"¿qué notario ha firmado el documento?\", 'context': \"DOS MIL TREINTA. En mi residencia, a quince de abril de dos mil quince. Ante mí, Paquito de los Palotes, notario del ilustre colegio de la Palmilla COMPARECEN Manolito y Jacinta para firmar la siguiente escritura de HERENCIA y para lo cual se sientan cómodamente.\"})\n",
    "\n",
    "tuned_pipeline(comprobando)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del modelo generado\n",
    "previo a la evaluación hay que hacer un Restart del entorno en VS Code... el sistema se me queda sin memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(SERVIDOR_MLFLOW)\n",
    "mlflow.autolog()\n",
    "mlflow.set_experiment(\"ENTRENAMIENTO Question-Answering\")\n",
    "\n",
    "split_test = 'test'\n",
    "test_dataset = main_dataset[split_test] # load_dataset('../Dataset/Escrituras','QA',trust_remote_code=True,split='validation')\n",
    "for ruta in tqdm([r for r in os.listdir('../Models/') if os.path.isdir('../Models/'+r)]):\n",
    "    if \"escrituras_QA\" in ruta:\n",
    "        ruta_modelo_ajustado = f\"../Models/{ruta}\"\n",
    "\n",
    "        modelo_ajustado = AutoModelForQuestionAnswering.from_pretrained(ruta_modelo_ajustado)\n",
    "        tokenizer_ajustado = AutoTokenizer.from_pretrained(ruta_modelo_ajustado)\n",
    "        val_batch_size = 512\n",
    "\n",
    "        with mlflow.start_run(run_name=\"VALIDACIÓN\",description=\"Validación del modelo ajustado\"):\n",
    "            # Definición del pipeline y el conjunto de datos\n",
    "            qc_dataset_test = [{'question':q, 'context':c} for q,c in zip(test_dataset['question'],test_dataset['context'])]\n",
    "            consulta_qc = pipeline(\"question-answering\", model=modelo_ajustado, tokenizer=tokenizer_ajustado, \n",
    "                            device=0 if torch.cuda.is_available() else None, batch_size=val_batch_size)\n",
    "            # Ejecución y cálculo de métricas\n",
    "            predicciones = consulta_qc(qc_dataset_test)\n",
    "            # exact_scores, f1_scores  = get_raw_scores(test_dataset,predicciones)\n",
    "            gold_answers = [answer[0] for answer in test_dataset['answers']]\n",
    "            f1_scores = compute_f1(gold_answers,predicciones)\n",
    "            exact_scores = compute_exact(gold_answers, predicciones)\n",
    "            \n",
    "            f1_mean = mean(f1_scores.values())\n",
    "            exact_mean = mean(exact_scores.values())\n",
    "            \n",
    "            for param_name, param_value in ml_params.items():\n",
    "                mlflow.log_param(param_name, param_value)        \n",
    "            mlflow.log_param('split', split_test)\n",
    "            mlflow.log_param('finetuned_name', os.path.basename(modelo_ajustado.name_or_path))\n",
    "            mlflow.log_metric('f1', f1_mean)\n",
    "            mlflow.log_metric('exact', exact_mean)\n",
    "            print(modelo_ajustado.name_or_path)\n",
    "            print('\\tf1:', f1_mean)\n",
    "            print('\\texact:', exact_mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
